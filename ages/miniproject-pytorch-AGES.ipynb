{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4683a6-1e28-472d-bb36-66c33661f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff12ec",
   "metadata": {},
   "source": [
    "Most if not all of the files here will be contained in /media/data/BIAS/microbiome_GCN/AGES/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136075d",
   "metadata": {},
   "source": [
    "Note that if feature_importance has already been computed, then you can skip directly to the bottom where you load it with pickle.\\\n",
    "\\\n",
    "Also note that \"miniproject-feature-significance.py\" can be directly run to do everything at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52aa32-d103-4e25-b220-e8844ec9ac40",
   "metadata": {},
   "source": [
    "First we load all the prerequisite files, process them and also grab some of information we will need down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b2dad-90cb-4f6d-8a50-b268621138dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"/media/data/BIAS/microbiome_GCN/AGES/AGP_ages.metadata.txt\", sep='\\t')\n",
    "df_meta = df_meta.set_index(\"#SampleID\")\n",
    "\n",
    "labels = df_meta['age_cat']  # the classes for the variable age_cat are the following: ['20s','30s','40s','50s','60s'] \n",
    "Sample_ids = labels.keys()\n",
    "\n",
    "df_AGES = pd.read_csv(\"/media/data/BIAS/microbiome_GCN/AGES/AGP.data.biom.filtered.ages.tsv\",sep='\\t')\n",
    "features = df_AGES[\"#OTU ID\"]\n",
    "df_AGES = df_AGES.set_index(\"#OTU ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af13c7e",
   "metadata": {},
   "source": [
    "loading the reference phylogeny which we will use to identify the RELATIONSHIP between the abundance of the different microbes (sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e236b-02e9-46da-b44a-401d651d92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gg_phylogeny = TreeNode.read(\"../../2024.09.phylogeny.asv.nwk\") #for now you don't actually need to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea52717",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict = pickle.load(open(\"/media/data/BIAS/microbiome_GCN/AGES/MATRICES_AGES.pickle\", \"rb\"))['TreeDistMatrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf9e89-d808-4aa9-8650-ff7f638764ee",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now, we have our labels (the class labels corresponding to each sample ID), and the abundance of each microbe. So we are at the point where we start feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcf976-68e8-4403-9a1d-eb766c687310",
   "metadata": {},
   "source": [
    "1. we will need to normalize the abundance: you can divide each value of the abundance table by the total sum of microbes observed in that sample.\n",
    "2. The order within each abundance vector will not matter for some methods, but will matter for others. For methods for which it matters, you will want to reorder the rows of the table via hierarchical clustering, using the distances in the distance matrix. The order should be fixed for all vectors.\n",
    "3. We will need to convert the two dataframes into machine-learning compatible data types, so make sure the labels are in the same order as the columns of the abundance table, then convert to a dataset of X and Y, where X is a list of vectors, and Y is a vector where each index matches an index of X. You will probably need to convert the class labels to integers.\n",
    "4. Then I guess we could start by trying to see if there is a signal with a very basic method, random forests, using the scikit-learn library ?\n",
    "5. Then, we could try XGBoost (using the XGBoost Library).\n",
    "\n",
    "For each, try many parameters to see if you get any significant signal (significantly more than 20%\n",
    "\n",
    "Then we meet to see what results we got"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea234485",
   "metadata": {},
   "source": [
    "We actually do not end up using XGBoost in the end, as it and support vector machines are significantly less accurate than random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68901ab",
   "metadata": {},
   "source": [
    "First, we define a dendrogram function to draw our clusters later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = numpy.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = numpy.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50675c",
   "metadata": {},
   "source": [
    "We then then use hierarchical clustering to see the number of clusters of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(dist_dict)\n",
    "dist_mat = numpy.zeros(shape=(n, n))\n",
    "\n",
    "for i, list_of_dists in enumerate(dist_dict.values()):\n",
    "    for j, dists in enumerate(list_of_dists.values()):\n",
    "        dist_mat[i][j] = dists\n",
    "\n",
    "hierarchical_clustering = AgglomerativeClustering(distance_threshold=0, n_clusters=None, metric='precomputed', linkage='average')\n",
    "hierarchical_clustering.fit(dist_mat)\n",
    "\n",
    "plt.title(\"Dendrogram of clusters\")\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(hierarchical_clustering, truncate_mode=\"level\", p=4)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c61dd8",
   "metadata": {},
   "source": [
    "It appears that a good number of nodes would be around 16\\\n",
    "Using this, we bin each feature into a cluster as to reorder the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a82239",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 16\n",
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=num_nodes, metric='precomputed', linkage='average')\n",
    "hierarchical_clustering.fit(dist_mat)\n",
    "hierarchical_clustering.labels_\n",
    "\n",
    "clusters = [[] for _ in range(num_nodes)]\n",
    "\n",
    "# send the ith term to their respective cluster\n",
    "for index, cluster in enumerate(hierarchical_clustering.labels_):\n",
    "    clusters[cluster].append(features[index])\n",
    "new_order = []\n",
    "for cluster in clusters:\n",
    "    new_order = new_order + cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d52321",
   "metadata": {},
   "source": [
    "Now we reorder the features, then we take the transpose of df_AGES to get the features to be horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ages_df = df_AGES.loc[new_order].T\n",
    "ordered_ages_df\n",
    "# X = df_AGES_percentage.loc[selected_features].T\n",
    "# X "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c103fb",
   "metadata": {},
   "source": [
    "It appears there are some samples that have zeroes across all features, we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4651cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ages_df = ordered_ages_df.loc[~((ordered_ages_df == 0).all(axis='columns'))]\n",
    "labels = labels[ordered_ages_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5f3e9",
   "metadata": {},
   "source": [
    "now, we normalize each row into a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = ordered_ages_df.sum(axis='columns')\n",
    "ages_percentage_df = (ordered_ages_df.div(sum, axis='index'))\n",
    "ages_percentage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f733561",
   "metadata": {},
   "source": [
    "Then we select features.\\\n",
    "Idea behind the criterion below is that we want to find features where there is a large difference between an age's average value for that feature and other ages' features. \\\n",
    "Standard deviation is used because mean may yield small values despite having large differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae54e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODINGS = {x : i for i, x in enumerate(sorted(ages_percentage_df.keys()))}\n",
    "ENCODINGS\n",
    "relabeled = ages_percentage_df.rename(mapper=ENCODINGS, axis='columns')\n",
    "\n",
    "selected_features = set()\n",
    "for i, age in enumerate(labels.unique()):\n",
    "    own_deviation = relabeled.loc[labels[labels == age].index].std()\n",
    "    other_deviation = relabeled.loc[labels[labels != age].index].std()\n",
    "    evaluation = (own_deviation - other_deviation) ** 2\n",
    "    selected_features |= set(list(evaluation.sort_values(ascending=False).iloc[0:700].index))\n",
    "\n",
    "selected_features = list(selected_features)\n",
    "\n",
    "selected_ages_df = relabeled.loc[:, selected_features]\n",
    "selected_ages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e665a",
   "metadata": {},
   "source": [
    "Now we prepare our predictors 'X' and our labels 'y', using a test/train split of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80545bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_ENCODINGS = {x : i for i, x in enumerate(sorted(labels.unique()))}\n",
    "y = labels.map(AGE_ENCODINGS).reindex(selected_ages_df.index)\n",
    "\n",
    "X = selected_ages_df.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10 , random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03978667",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=11, n_estimators=200)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a789720",
   "metadata": {},
   "source": [
    "Here is the lengthiest part, we use permutation importance to find the most significant predictor of each age category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ba32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "results = {}\n",
    "for cls in AGE_ENCODINGS.values():\n",
    "    mask = y_train == cls\n",
    "    imp = permutation_importance(random_forest, X_train[mask], y_train[mask], n_repeats=1)\n",
    "    results[cls] = imp.importances_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152b358",
   "metadata": {},
   "source": [
    "Then convert it back into a format that's readable to humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169806c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_encodings = {v: k for k, v in ENCODINGS.items()}\n",
    "importance = {}\n",
    "for age in results:\n",
    "    temp = results[age]\n",
    "    temp = {inv_encodings[i]: imp for i, imp in enumerate(temp)}\n",
    "    temp = dict(sorted(temp.items(), key=lambda item: item[1], reverse=True))\n",
    "    importance[sorted(labels.unique())[age]] = temp\n",
    "\n",
    "with open(\"./feature_importance.pkl\", \"wb\") as file:\n",
    "    pickle.dump(importance, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af6c02f",
   "metadata": {},
   "source": [
    "We can then load the importance matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1271d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./feature_importance.pkl', 'rb') as file:\n",
    "    importance = pickle.load(file)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c9f6e",
   "metadata": {},
   "source": [
    "Importance contains how important each OTU is for determining the age category of the person, positive means people tend to be more likely to be the category if they have higher values of that OTU. Negative means people are less likely to be in category for higher values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
